{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "CV",
   "id": "602a5d8bc6b940f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T10:37:32.624480Z",
     "start_time": "2025-10-05T10:37:32.246979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from CV_train import EfficientNet, CVDataset\n",
    "from torch.utils import data"
   ],
   "id": "8f4ea53ae0c30d58",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:04:54.341400Z",
     "start_time": "2025-10-03T15:04:38.360625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "en_b0 = EfficientNet()\n",
    "animals_10_dataset = CVDataset(\"data/raw-img\", 0.2, 0.1, en_b0.connector)\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    data.Subset(animals_10_dataset, animals_10_dataset.train_index),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True)\n",
    "eval_dataloader = data.DataLoader(\n",
    "    data.Subset(animals_10_dataset, animals_10_dataset.eval_index),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True)\n",
    "test_dataloader = data.DataLoader(\n",
    "    data.Subset(animals_10_dataset, animals_10_dataset.test_index),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True)"
   ],
   "id": "b64f1dc7feb20557",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file, folder: e83db7072afd013ed1584d05fb1d4e9fe777ead218ac104497f5c978a4eebdbd_640.jpg, elephant\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:04:54.384224Z",
     "start_time": "2025-10-03T15:04:54.377993Z"
    }
   },
   "cell_type": "code",
   "source": "len(train_dataloader)",
   "id": "575c3b8248194ae4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:06:14.005885Z",
     "start_time": "2025-10-03T15:04:54.448281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "new_en_b0 = EfficientNet(new_head = True)\n",
    "new_en_b0.train(train_dataloader, eval_dataloader, train_steps = 600)\n",
    "new_en_b0.save(\"models/new_en_b0_first_run.pt\")"
   ],
   "id": "8a1c83227173be37",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:06:14.311951Z",
     "start_time": "2025-10-03T15:06:14.057759Z"
    }
   },
   "cell_type": "code",
   "source": "mat, rep = new_en_b0.eval_statistics(test_dataloader)",
   "id": "d1a0125c9b55d2d5",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:06:14.321762Z",
     "start_time": "2025-10-03T15:06:14.317936Z"
    }
   },
   "cell_type": "code",
   "source": "print(mat)",
   "id": "19933d3c04257488",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 22  0  0  0  0  0  0  0  1]\n",
      " [ 0  0 27  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 17  1  0  0  0  0  0]\n",
      " [ 0  0  0  0 18  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 15  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 21  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 21  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 12  0]\n",
      " [ 0  0  1  0  0  0  0  0  0 18]]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:06:14.343719Z",
     "start_time": "2025-10-03T15:06:14.340220Z"
    }
   },
   "cell_type": "code",
   "source": "print(rep)",
   "id": "d84dd927297d2e5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   butterfly       1.00      1.00      1.00        18\n",
      "         cat       1.00      0.96      0.98        23\n",
      "     chicken       0.96      1.00      0.98        27\n",
      "         cow       1.00      0.94      0.97        18\n",
      "         dog       0.95      1.00      0.97        18\n",
      "    elephant       1.00      1.00      1.00        15\n",
      "       horse       1.00      1.00      1.00        21\n",
      "       sheep       1.00      1.00      1.00        21\n",
      "      spider       1.00      1.00      1.00        12\n",
      "    squirrel       0.95      0.95      0.95        19\n",
      "\n",
      "    accuracy                           0.98       192\n",
      "   macro avg       0.99      0.98      0.99       192\n",
      "weighted avg       0.98      0.98      0.98       192\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:06:14.705583Z",
     "start_time": "2025-10-03T15:06:14.425508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "new_new_en_b0 = EfficientNet(new_head = True)\n",
    "new_new_en_b0.load(\"models/new_en_b0_test.pt\")"
   ],
   "id": "aed3f4f344ebe225",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "NER",
   "id": "82265b806bf52076"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "ner\n",
    "nli\n",
    "clip-ner\n",
    "clip-bow"
   ],
   "id": "ddc435b45bba3aa1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ner based approach",
   "id": "776cc60b512f8864"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T10:37:34.868090Z",
     "start_time": "2025-10-05T10:37:34.861691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#I used LLM for generating presets and with prompt :\" prompt here\"\n",
    "def generate_uni_test_template(animal_name):\n",
    "    test_presets = [\n",
    "        f\"Look! A majestic {animal_name} is visible\", #base\n",
    "        f\"I think there might be a {animal_name} in this photo\",#base\n",
    "        f\"Is this a picture of a {animal_name}\",#base\n",
    "        f\"The picture features a big, brown {animal_name}\", #base\n",
    "        f\"I'm looking for a {animal_name}. Is it here?\",#base\n",
    "        f\"It's a {animal_name}! I'm sure of it\", #base\n",
    "        f\"An {animal_name} can be seen on the left side\", #base\n",
    "        f\"There is a {animal_name} grazing in the field\" #base*(if we want to answer on all possible questions including the env it's only possible with zero-shot image classifiers like CLIP)\n",
    "        f\"This animal is definitely a {animal_name}\" #base\n",
    "        f\"I don't see a {animal_name} anywhere\", #negative example that breaks our model because of NER structure\n",
    "        f\"A cute little {animal_name} is on the branch\" #base\n",
    "        f\"The photo contains an animal; I believe it's a {animal_name}\", #base\n",
    "        f\"This is a great picture of a human and an {animal_name}\", #multiple ents\n",
    "        f\"Can you confirm that this isn't a {animal_name}?\", #negative example that breaks our model because of NER structure\n",
    "        f\"This is a {'-'.join(animal_name)}\", #misstypo\n",
    "        f\"{animal_name}.\" #base\n",
    "    ]\n",
    "    return test_presets\n",
    "\n",
    "def denial_uni_test(animal_name):\n",
    "    test_presets = [\n",
    "        f\"I don't see a {animal_name} anywhere\", #negative example that breaks our model because of NER structure\n",
    "        f\"Can you confirm that this isn't a {animal_name}?\", #negative example that breaks our model because of NER structure\n",
    "    ]\n",
    "    return test_presets\n",
    "\n",
    "def generate_bi_test_template(label, decoy):\n",
    "    test_presets = [\n",
    "        f\"There appears to be a {label} or a {decoy}\", #multiple ents\n",
    "        f\"I saw a {label} on this picture and a small {decoy} earlier\", #multiple ents\n",
    "    ]\n",
    "    return test_presets"
   ],
   "id": "b12751f7c2d3b5ad",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T10:37:42.870134Z",
     "start_time": "2025-10-05T10:37:42.863040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "negative_labels = [\"apple\", \"plane\", \"axe\", \"student\", \"kurtosis\"]\n",
    "\n",
    "positive_labels = list(CVDataset.label_to_index.keys())\n",
    "positive_labels.remove(\"NoF\")\n",
    "positive_labels"
   ],
   "id": "ea50a6ac93237510",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['butterfly',\n",
       " 'cat',\n",
       " 'chicken',\n",
       " 'cow',\n",
       " 'dog',\n",
       " 'elephant',\n",
       " 'horse',\n",
       " 'sheep',\n",
       " 'spider',\n",
       " 'squirrel']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T10:37:43.666877Z",
     "start_time": "2025-10-05T10:37:43.659887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "animals_combination = list(itertools.product(positive_labels, positive_labels))\n",
    "entity_combination = list(itertools.product(positive_labels, negative_labels))\n",
    "eval_corpus_features = []\n",
    "eval_corpus_targets = []\n",
    "\n",
    "for names in animals_combination:\n",
    "    label = names[0]\n",
    "    decoy = names[1]\n",
    "    if label == decoy:\n",
    "        uni_examples = generate_uni_test_template(label)\n",
    "        eval_corpus_features.extend(uni_examples)\n",
    "        eval_corpus_targets.extend(np.ones(len(uni_examples)) * CVDataset.label_to_index[label])\n",
    "\n",
    "        uni_examples = denial_uni_test(label)\n",
    "        eval_corpus_features.extend(uni_examples)\n",
    "        eval_corpus_targets.extend(np.ones(len(uni_examples)) * CVDataset.label_to_index['NoF'])\n",
    "    else:\n",
    "        bi_examples = generate_bi_test_template(label, decoy)\n",
    "        eval_corpus_features.extend(bi_examples)\n",
    "        eval_corpus_targets.extend(np.ones(len(bi_examples)) * CVDataset.label_to_index[label])\n",
    "\n",
    "for names in entity_combination:\n",
    "    label = names[0]\n",
    "    decoy = names[1]\n",
    "\n",
    "    bi_examples = generate_bi_test_template(label, decoy)\n",
    "    eval_corpus_features.extend(bi_examples)\n",
    "    eval_corpus_targets.extend(np.ones(len(bi_examples)) * CVDataset.label_to_index[label])"
   ],
   "id": "277cbbba3a2b863f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T10:37:46.944912Z",
     "start_time": "2025-10-05T10:37:46.940923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ner_classes = positive_labels\n",
    "nli_classes = []\n",
    "for animal in ner_classes:\n",
    "    nli_classes.extend([f\"there is a {animal}\", f\"there is no {animal}\"])"
   ],
   "id": "79155be5f4ccefc4",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "NER",
   "id": "92ca6c93f4c428fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T08:36:52.451001Z",
     "start_time": "2025-10-05T08:36:08.438421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gliner import GLiNER\n",
    "\n",
    "model = GLiNER.from_pretrained(\"gliner-community/gliner_large-v2.5\", load_tokenizer=True)\n",
    "\n",
    "import torch\n",
    "model.to(torch.device(\"cuda:0\"))\n",
    "text = eval_corpus_features\n",
    "\n",
    "predictions = []\n",
    "labels = ner_classes\n",
    "for line in text:\n",
    "    prediction = model.predict_entities(line, labels, threshold = 0.75)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "predicted_labels = []\n",
    "for prediction in predictions:\n",
    "    try:\n",
    "        label = prediction[0][\"label\"]\n",
    "        predicted_labels.append(label)\n",
    "    except:\n",
    "        predicted_labels.append(\"NoF\")"
   ],
   "id": "142fa5e6c60fb05c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andry\\anaconda3\\envs\\tired_of_wins\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 10 files: 100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T09:09:55.943647Z",
     "start_time": "2025-10-05T09:09:55.936571Z"
    }
   },
   "cell_type": "code",
   "source": "print(model.data_processor)",
   "id": "621d101df2e7cec1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gliner.data_processing.processor.SpanProcessor object at 0x0000024C388C5190>\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.model.token_rep_layer.encode_text() #encoder from GLiNER",
   "id": "c3eff8d0c12a8c26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T16:52:50.520655Z",
     "start_time": "2025-10-04T16:52:50.516926Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 35,
   "source": "predicted_ids = [CVDataset.label_to_index[label] for label in predicted_labels]",
   "id": "f33cf98ac001ea34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T16:52:51.808864Z",
     "start_time": "2025-10-04T16:52:51.791785Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 36,
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(eval_corpus_targets, predicted_ids)\n",
    "conf_report = classification_report(eval_corpus_targets, predicted_ids, target_names=CVDataset.label_to_index.keys())"
   ],
   "id": "6fb45a2b09c3d54c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T16:52:53.987395Z",
     "start_time": "2025-10-04T16:52:53.982665Z"
    }
   },
   "cell_type": "code",
   "source": "conf_matrix",
   "id": "de1a01ab6bdd18c4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3],\n",
       "       [ 0, 38,  0,  0,  0,  0,  0,  0,  0,  0,  3],\n",
       "       [ 0,  0, 38,  0,  0,  0,  0,  0,  0,  0,  3],\n",
       "       [ 0,  0,  0, 39,  0,  0,  0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0, 38,  0,  0,  0,  0,  0,  3],\n",
       "       [ 0,  0,  0,  0,  0, 38,  0,  0,  0,  0,  3],\n",
       "       [ 0,  0,  0,  0,  0,  0, 38,  0,  0,  0,  3],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 38,  0,  0,  3],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 39,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 38,  3],\n",
       "       [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  0]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T16:52:59.758932Z",
     "start_time": "2025-10-04T16:52:59.754712Z"
    }
   },
   "cell_type": "code",
   "source": "print(conf_report)",
   "id": "b079efbb412ae1f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   butterfly       0.95      0.93      0.94        41\n",
      "         cat       0.95      0.93      0.94        41\n",
      "     chicken       0.95      0.93      0.94        41\n",
      "         cow       0.95      0.95      0.95        41\n",
      "         dog       0.95      0.93      0.94        41\n",
      "    elephant       0.95      0.93      0.94        41\n",
      "       horse       0.95      0.93      0.94        41\n",
      "       sheep       0.95      0.93      0.94        41\n",
      "      spider       0.95      0.95      0.95        41\n",
      "    squirrel       0.95      0.93      0.94        41\n",
      "         NoF       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.89       430\n",
      "   macro avg       0.86      0.85      0.86       430\n",
      "weighted avg       0.91      0.89      0.90       430\n",
      "\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "NLI based approach",
   "id": "15e38f9e1651319f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T20:05:47.749439Z",
     "start_time": "2025-10-04T19:44:57.296924Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "execution_count": 50,
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "text = eval_corpus_features\n",
    "\n",
    "predictions = []\n",
    "labels = nli_classes\n",
    "line = text[2]\n",
    "\n",
    "for line in text:\n",
    "    prediction = classifier(line, labels)\n",
    "    prediction = prediction[\"labels\"][0]\n",
    "    predictions.append(prediction)"
   ],
   "id": "bebd5da87018653b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T20:14:41.287421Z",
     "start_time": "2025-10-04T20:14:41.284246Z"
    }
   },
   "cell_type": "code",
   "source": "predicted_nli_ids = [nli_classes.index(label) for label in predictions]",
   "id": "296f67e44d1f9c78",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T20:29:52.450553Z",
     "start_time": "2025-10-04T20:29:52.445346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corrected_predictions = []\n",
    "for target, predicted in zip(eval_corpus_targets, predicted_nli_ids):\n",
    "    if target == predicted/2:\n",
    "        corrected_predictions.append(target)\n",
    "    elif target == (predicted-1)/2:\n",
    "        corrected_predictions.append(10)\n",
    "    elif predicted%2 == 0:\n",
    "        corrected_predictions.append(predicted/2)\n",
    "    else:\n",
    "        corrected_predictions.append(target)"
   ],
   "id": "c550ae88acb6eb27",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T20:29:54.091978Z",
     "start_time": "2025-10-04T20:29:54.075577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(eval_corpus_targets, corrected_predictions)\n",
    "conf_report = classification_report(eval_corpus_targets, corrected_predictions, target_names=CVDataset.label_to_index.keys())\n",
    "conf_matrix"
   ],
   "id": "bd968afbdd08ce02",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0, 40,  0,  0,  0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0, 40,  0,  0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0, 40,  0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 1,  0,  0,  0, 38,  0,  0,  0,  1,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0, 40,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0, 40,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 39,  1,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 40,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 40,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 20]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T20:29:54.875305Z",
     "start_time": "2025-10-04T20:29:54.870655Z"
    }
   },
   "cell_type": "code",
   "source": "print(conf_report)",
   "id": "1bc7966316aff4c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   butterfly       0.98      0.98      0.98        41\n",
      "         cat       1.00      0.98      0.99        41\n",
      "     chicken       1.00      0.98      0.99        41\n",
      "         cow       1.00      0.98      0.99        41\n",
      "         dog       1.00      0.93      0.96        41\n",
      "    elephant       1.00      0.98      0.99        41\n",
      "       horse       1.00      0.98      0.99        41\n",
      "       sheep       1.00      0.95      0.97        41\n",
      "      spider       0.95      0.98      0.96        41\n",
      "    squirrel       1.00      0.98      0.99        41\n",
      "         NoF       0.67      1.00      0.80        20\n",
      "\n",
      "    accuracy                           0.97       430\n",
      "   macro avg       0.96      0.97      0.96       430\n",
      "weighted avg       0.98      0.97      0.97       430\n",
      "\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "CLIP (2nd head for ner and CV) based approach",
   "id": "3aab4f0cb7acb993"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:34:24.899265Z",
     "start_time": "2025-10-05T13:34:08.939453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gliner import GLiNER\n",
    "from transformers import AutoTokenizer\n",
    "gliner = GLiNER.from_pretrained(\"gliner-community/gliner_large-v2.5\", load_tokenizer=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(gliner.config.model_name) #tokenizer for gliner\n",
    "encoder = gliner.model.token_rep_layer#.encode_text() #encoder from GLiNER\n",
    "\n"
   ],
   "id": "dd7acb6c27419ce1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 10 files: 100%|██████████| 10/10 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "execution_count": 180
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:34:24.914229Z",
     "start_time": "2025-10-05T13:34:24.907954Z"
    }
   },
   "cell_type": "code",
   "source": "eval_corpus_features[0]",
   "id": "d996bcd83fa721c3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Look! A majestic butterfly is visible'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 181
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:34:50.326166Z",
     "start_time": "2025-10-05T13:34:50.321179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_input = tokenizer(eval_corpus_features[0])\n",
    "        #     is_split_into_words=True,\n",
    "        #     return_tensors=\"pt\",\n",
    "        #     truncation=True,\n",
    "        #     padding=\"longest\",\n",
    "        # )"
   ],
   "id": "d2fec91493a9f944",
   "outputs": [],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:34:50.754656Z",
     "start_time": "2025-10-05T13:34:50.751351Z"
    }
   },
   "cell_type": "code",
   "source": "tokenized_input = tokenized_input\n",
   "id": "ebf9ccc3eea9c861",
   "outputs": [],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:34:51.393409Z",
     "start_time": "2025-10-05T13:34:51.389024Z"
    }
   },
   "cell_type": "code",
   "source": "tokenized_input",
   "id": "56c6bcc0ebe6fe44",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 3413, 300, 336, 17889, 13843, 269, 3979, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 187
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T11:01:17.983342Z",
     "start_time": "2025-10-05T11:01:17.978508Z"
    }
   },
   "cell_type": "code",
   "source": "tokenized_input.input_ids",
   "id": "7550514266ec9901",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3413, 300, 336, 17889, 13843, 269, 3979, 2]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:37:38.070405Z",
     "start_time": "2025-10-05T13:37:38.063936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gliner.data_processing.collator import DataCollator\n",
    "\n",
    "def run(\n",
    "    self, texts, labels = [''], flat_ner=True, threshold=0.5, multi_label=False, batch_size=1,\n",
    "    gen_constraints = None, num_gen_sequences = 1, **gen_kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Predict entities for a batch of texts.\n",
    "\n",
    "    Args:\n",
    "        texts (List[str]): A list of input texts to predict entities for.\n",
    "        labels (List[str]): A list of labels to predict.\n",
    "        flat_ner (bool, optional): Whether to use flat NER. Defaults to True.\n",
    "        threshold (float, optional): Confidence threshold for predictions. Defaults to 0.5.\n",
    "        multi_label (bool, optional): Whether to allow multiple labels per token. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        The list of lists with predicted entities.\n",
    "    \"\"\"\n",
    "    self.eval()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(gliner.config.model_name)\n",
    "    tokenized_input = tokenizer(texts[0])\n",
    "    batch = tokenized_input\n",
    "    print(batch)\n",
    "    outputs = []\n",
    "        #model_output = self.model(**batch, threshold=threshold, output_hidden_states = True)\n",
    "\n",
    "\n",
    "                        #gliner(->).SpanModel(-).Encoder(<-).Transformer(<-).DebertaV2Model(<-).DebertaEmbeddings.forward()\n",
    "        #meanwhile what I want is gliner(->).SpanModel(-).Encoder(<-).Transformer(<-).DebertaV2Model(<-).forward() -> self.linear(self.pooler())\n",
    "    model_output = self.model.token_rep_layer.bert_layer.model(\n",
    "        input_ids = torch.tensor([batch[\"input_ids\"]]),\n",
    "        attention_mask = torch.tensor([batch[\"attention_mask\"]]),\n",
    "        token_type_ids = torch.tensor([batch[\"token_type_ids\"]]),\n",
    "        #threshold=threshold,\n",
    "    ), #output_hidden_states = True,\n",
    "                                        #return_dict = True)\n",
    "    outputs.append(model_output)\n",
    "    return outputs"
   ],
   "id": "46c2044d9b6f447b",
   "outputs": [],
   "execution_count": 194
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:37:40.147465Z",
     "start_time": "2025-10-05T13:37:38.524082Z"
    }
   },
   "cell_type": "code",
   "source": "outputs = run(gliner, [eval_corpus_features[0]])",
   "id": "7ba41d9a6149080b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1, 3413, 300, 336, 17889, 13843, 269, 3979, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:37:42.717859Z",
     "start_time": "2025-10-05T13:37:42.712393Z"
    }
   },
   "cell_type": "code",
   "source": "outputs[0][0].last_hidden_state[:,0].shape",
   "id": "795ff22852dcd2ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 196
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T12:26:16.064214Z",
     "start_time": "2025-10-05T12:26:16.059697Z"
    }
   },
   "cell_type": "code",
   "source": "[eval_corpus_features[0]]",
   "id": "789bbed25427ab1e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Look! A majestic butterfly is visible']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T12:26:16.352152Z",
     "start_time": "2025-10-05T12:26:16.347763Z"
    }
   },
   "cell_type": "code",
   "source": "outputs[0][\"logits\"].shape",
   "id": "761071e941adadaa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 12, 1])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T12:26:16.560927Z",
     "start_time": "2025-10-05T12:26:16.556434Z"
    }
   },
   "cell_type": "code",
   "source": "outputs[0][\"prompts_embedding\"].shape",
   "id": "60a4ddef3935c389",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 768])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T12:26:16.771350Z",
     "start_time": "2025-10-05T12:26:16.765978Z"
    }
   },
   "cell_type": "code",
   "source": "outputs[0][\"words_embedding\"].shape",
   "id": "e5d9345b5015e62",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 768])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b072cac477e41591"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
