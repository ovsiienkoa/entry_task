{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T10:09:54.150994Z",
     "start_time": "2025-10-03T10:09:54.146580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms as T\n",
    "from torchvision.io import decode_image\n",
    "from torchvision import models\n",
    "\n",
    "from torch.utils import data\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "45d87ec5836da2b0",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T11:18:02.618454Z",
     "start_time": "2025-10-03T11:18:02.613059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# default SimCLR augmentation (code from BYOL, because I like it)\n",
    "import random\n",
    "class RandomApply(nn.Module):\n",
    "    def __init__(self, fn, p):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.p = p\n",
    "    def forward(self, x):\n",
    "        if random.random() > self.p:\n",
    "            return x\n",
    "        return self.fn(x)\n",
    "\n",
    "DEFAULT_AUG = torch.nn.Sequential(\n",
    "    RandomApply(\n",
    "        T.ColorJitter(0.8, 0.8, 0.8, 0.2),\n",
    "        p=0.3\n",
    "    ),\n",
    "    T.RandomGrayscale(p=0.2),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    RandomApply(\n",
    "        T.GaussianBlur((3, 3), (1.0, 2.0)),\n",
    "        p=0.2\n",
    "    )\n",
    ")"
   ],
   "id": "a1dc3369a4dd4079",
   "outputs": [],
   "execution_count": 166
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T11:18:02.879305Z",
     "start_time": "2025-10-03T11:18:02.871369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CVDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    label_to_index = { #in comments imagenet ids\n",
    "            'butterfly':0, #322\n",
    "             'cat':1, #too many different cars\n",
    "             'chicken':2, #7 cock\n",
    "             'cow':3,\n",
    "             'dog':4,\n",
    "             'elephant':5, # 385 indian elephant\n",
    "             'horse':6,\n",
    "             'sheep':7,\n",
    "             'spider':8,\n",
    "             'squirrel':9\n",
    "        }\n",
    "\n",
    "    def __init__(self, folder_path:str, eval_size:float, test_size:float, connector:T):\n",
    "        super().__init__()\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "        self.train_index = None\n",
    "        self.test_index = None\n",
    "        self.eval_index = None\n",
    "\n",
    "\n",
    "        for folder in os.listdir(folder_path):\n",
    "\n",
    "            target = torch.zeros(10)\n",
    "            target[CVDataset.label_to_index[folder]] = 1\n",
    "            expected_number_of_files = len(os.listdir(os.path.join(folder_path, folder))[:500]) * 2#*2 because we create to copies with different augs #[:500] only because I have 16 gb of ram\n",
    "            errors_counter = 0\n",
    "\n",
    "            for file in os.listdir(f\"{folder_path}/{folder}\")[:500]: #[:500] - 16 gb of ram\n",
    "\n",
    "                image_tensor = decode_image(f\"{folder_path}/{folder}\"+\"/\"+file)\n",
    "                try:\n",
    "                    self.data.append(DEFAULT_AUG(connector(image_tensor[:3, :, :]))) #[:3], because png pics have 4 channels and the last one is redundant\n",
    "                    self.data.append(DEFAULT_AUG(connector(image_tensor[:3, :, :])))\n",
    "                except RuntimeError:\n",
    "                    errors_counter +=1\n",
    "                    print(f\"file, folder: {file}, {folder}\")\n",
    "\n",
    "            target = target.expand(expected_number_of_files - 2*errors_counter, 10)\n",
    "            self.targets.extend(target)\n",
    "\n",
    "        self.data = torch.stack(self.data, dim = 0)\n",
    "        self.targets = torch.stack(self.targets, dim = 0)\n",
    "\n",
    "        self.train_index, self.eval_index = train_test_split(np.arange(0, len(self.targets)), test_size=(test_size+eval_size), random_state=42)\n",
    "        self.eval_index, self.test_index = train_test_split(self.eval_index, test_size= test_size / (test_size+eval_size), random_state=42)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.targets[index]"
   ],
   "id": "b909186b5bf1387",
   "outputs": [],
   "execution_count": 167
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T11:18:03.904483Z",
     "start_time": "2025-10-03T11:18:03.892753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EfficientNet:\n",
    "    def __init__(self, new_head:bool = False):\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.base_conf = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "        self.model = models.efficientnet_b0(weights = self.base_conf)\n",
    "        self.connector = self.base_conf.transforms()\n",
    "         #I do understand, that ImageNet has these classes that I am willing to train on, but considering the quality of ImageNet (todo paste promo link) it won't bother to finetune tiny model\n",
    "        if new_head:\n",
    "            self.model.classifier = nn.Sequential(\n",
    "                nn.Dropout(p=0.2, inplace=True),\n",
    "                nn.Linear(in_features=1280, out_features=10, bias=True) #todo weight init\n",
    "            )\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.003)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def train(self, train_dataloader:data.DataLoader, eval_dataloader:data.DataLoader, train_steps:int):\n",
    "\n",
    "        #freezing backbone\n",
    "        for param in self.model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        writer = SummaryWriter()\n",
    "        for batch in range(train_steps):\n",
    "            cum_loss = 0  # cumulative loss for plot\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            features, targets = next(iter(train_dataloader))\n",
    "            features = features.to(self.device)\n",
    "\n",
    "            prediction = self.model(features)\n",
    "            output = self.loss(prediction, targets.to(self.device))\n",
    "            cum_loss += output.item()\n",
    "            output.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if batch % 20 == 0:\n",
    "                avg_val_loss = self.eval(eval_dataloader)\n",
    "                writer.add_scalars(f'loss', {\"train\": cum_loss/ 20, \"eval\": avg_val_loss}, batch)\n",
    "\n",
    "        writer.close()\n",
    "\n",
    "    def eval(self, dataloader:data.DataLoader) -> float:\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            val_loss = 0\n",
    "            for batch in dataloader:\n",
    "                features, targets = batch\n",
    "                features = features.to(self.device)\n",
    "                prediction = self.model(features)\n",
    "                output = self.loss(prediction, targets.to(self.device))\n",
    "                val_loss += output.item()\n",
    "\n",
    "        return val_loss / len(dataloader)\n",
    "\n",
    "    def predict(self, inputs) -> torch.Tensor:\n",
    "        self.model.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            prediction = self.model(inputs.to(self.device))\n",
    "            prediction = torch.argmax(prediction, dim = 1)\n",
    "        return prediction\n",
    "\n",
    "    def eval_statistics(self, dataloader:data.DataLoader):\n",
    "        predicted_labels = []\n",
    "        target_labels = []\n",
    "        for batch in dataloader:\n",
    "            features, targets = batch\n",
    "            predicted_label = self.predict(features)\n",
    "            target_label = torch.argmax(targets, dim=1)\n",
    "\n",
    "            predicted_labels.extend(predicted_label.cpu().detach().numpy())\n",
    "            target_labels.extend(target_label.cpu().detach().numpy())\n",
    "\n",
    "        conf_matrix = confusion_matrix(target_labels, predicted_labels)\n",
    "        conf_report = classification_report(target_labels, predicted_labels, target_names=CVDataset.label_to_index.keys())\n",
    "        return conf_matrix, conf_report\n",
    "\n",
    "\n",
    "    def save(self, path:str):\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "        torch.save(self.optimizer.state_dict(), f\"{path[:-3]}_optim.pt\")\n",
    "\n",
    "    def load(self, path:str):\n",
    "        self.model.load_state_dict(torch.load(path, weights_only=True))\n",
    "        self.optimizer.load_state_dict(torch.load(f\"{path[:-3]}_optim.pt\", weights_only=True))"
   ],
   "id": "576dcbf8f83203ab",
   "outputs": [],
   "execution_count": 168
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T11:19:11.934752Z",
     "start_time": "2025-10-03T11:18:06.848025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "en_b0 = EfficientNet()\n",
    "animals_10_dataset = CVDataset(\"data/raw-img\", 0.2, 0.1, en_b0.connector)\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    data.Subset(animals_10_dataset, animals_10_dataset.train_index),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True)\n",
    "eval_dataloader = data.DataLoader(\n",
    "    data.Subset(animals_10_dataset, animals_10_dataset.eval_index),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True)\n",
    "test_dataloader = data.DataLoader(\n",
    "    data.Subset(animals_10_dataset, animals_10_dataset.test_index),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True)"
   ],
   "id": "b64f1dc7feb20557",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file, folder: e83db7072afd013ed1584d05fb1d4e9fe777ead218ac104497f5c978a4eebdbd_640.jpg, elephant\n"
     ]
    }
   ],
   "execution_count": 169
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T11:12:59.206036Z",
     "start_time": "2025-10-03T11:12:59.201455Z"
    }
   },
   "cell_type": "code",
   "source": "len(train_dataloader)",
   "id": "575c3b8248194ae4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 158
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T11:14:25.495166Z",
     "start_time": "2025-10-03T11:14:09.378184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "new_en_b0 = EfficientNet(new_head = True)\n",
    "new_en_b0.train(train_dataloader, eval_dataloader, train_steps = 160)\n",
    "new_en_b0.save(\"models/new_en_b0_first_run.pt\")"
   ],
   "id": "8a1c83227173be37",
   "outputs": [],
   "execution_count": 159
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T11:15:24.908531Z",
     "start_time": "2025-10-03T11:15:24.059385Z"
    }
   },
   "cell_type": "code",
   "source": "mat, rep = new_en_b0.eval_statistics(test_dataloader)",
   "id": "d1a0125c9b55d2d5",
   "outputs": [],
   "execution_count": 163
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T11:15:24.917451Z",
     "start_time": "2025-10-03T11:15:24.914023Z"
    }
   },
   "cell_type": "code",
   "source": "print(mat)",
   "id": "19933d3c04257488",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43  1  0  0  0  0  0  0  0  0]\n",
      " [ 0 44  0  0  0  0  0  0  0  1]\n",
      " [ 0  0 47  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 35  0  1  2  1  0  1]\n",
      " [ 0  1  1  1 29  0  1  0  0  0]\n",
      " [ 0  0  0  1  0 40  0  0  0  0]\n",
      " [ 0  0  0  1  0  0 34  0  0  0]\n",
      " [ 0  0  0  1  0  0  1 35  0  0]\n",
      " [ 3  0  1  0  0  0  2  0 22  1]\n",
      " [ 2  0  3  0  3  0  0  0  1 24]]\n"
     ]
    }
   ],
   "execution_count": 164
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T11:15:24.994753Z",
     "start_time": "2025-10-03T11:15:24.991695Z"
    }
   },
   "cell_type": "code",
   "source": "print(rep)",
   "id": "d84dd927297d2e5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   butterfly       0.90      0.98      0.93        44\n",
      "         cat       0.96      0.98      0.97        45\n",
      "     chicken       0.90      1.00      0.95        47\n",
      "         cow       0.90      0.88      0.89        40\n",
      "         dog       0.91      0.88      0.89        33\n",
      "    elephant       0.98      0.98      0.98        41\n",
      "       horse       0.85      0.97      0.91        35\n",
      "       sheep       0.97      0.95      0.96        37\n",
      "      spider       0.96      0.76      0.85        29\n",
      "    squirrel       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.92       384\n",
      "   macro avg       0.92      0.91      0.91       384\n",
      "weighted avg       0.92      0.92      0.92       384\n",
      "\n"
     ]
    }
   ],
   "execution_count": 165
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T10:34:53.710806Z",
     "start_time": "2025-10-03T10:34:53.372757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "new_new_en_b0 = EfficientNet(new_head = True)\n",
    "new_new_en_b0.load(\"models/new_en_b0_test.pt\")"
   ],
   "id": "aed3f4f344ebe225",
   "outputs": [],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T09:11:53.555881Z",
     "start_time": "2025-10-03T09:11:53.552873Z"
    }
   },
   "cell_type": "code",
   "source": "# en_b0.train(train_dataloader)",
   "id": "e594974412419746",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "en_b0.eval(test_dataloader)",
   "id": "87524e855e1d2401"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6a5c792d174aeb18"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
